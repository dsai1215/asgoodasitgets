We make the same assumptions as those used in the analysis of \cite{prashanth2015rdsa}, with a few minor alterations. The assumptions are listed below:
\begin{enumerate}[label=(\textbf{C\arabic*})]
\item  The function
$f$ is four-times differentiable\footnote{Here $\nabla^4 f(x) = \dfrac{\partial^4 f (x)}{\partial x\tr \partial x\tr \partial x\tr \partial x\tr}$ denotes the fourth derivate of $f$ at $x$ and $\nabla^4_{i_1 i_2 i_3 i_4} f(x)$ denotes the $(i_1 i_2 i_3 i_4)$th entry of $\nabla^4 f(x)$, for $i_1, i_2, i_3,i_4=1,\ldots, N$.} with $\left|\nabla^4_{i_1 i_2 i_3 i_4} f(x) \right| < \infty$, for $i_1, i_2, i_3,i_4=1,\ldots, N$ and for all $x\in \R^N$. 

%\item  For some $\rho>0$  and almost all $x_n$, the function $f$ is four-times differentiable with a uniformly (in $n$) bounded fourth derivative for all $x$ such that $\left\| x_n - x\right\| \le \rho$. 

\item For each $n$ and all $x$, there exists a $\rho>0$ not dependent on $n$ and $x$, such that $(x-x^*)\tr \bar f_n(x) \ge \rho \left\| x_n - x\right\|$, where $\bar f_n(x) = \Upsilon(\overline H_n)^{-1} \nabla f(x)$.

\item $\{\xi_n, \xi_n^+,\xi_n^-, n=1,2,\ldots\}$ are such that, for all $n$, $\E\left[\left. \xi_n^+ + \xi_n^- - 2 \xi_n \right| \F_n\right] = 0$, where $\mathcal{F}_n = \sigma(x_m,m\le n)$ denotes the underlying sigma-field.. 

\item $\{d_n^i, i=1,\ldots,N, n=1,2,\ldots\}$ are i.i.d. and independent of $\F_n$.

\item  The step-sizes $a_n$ and perturbation constants $\delta_n$ are positive, for all $n$ and satisfy
$$\hspace{-1.7em} a_n, \delta_n \rightarrow 0\text{ as } n \rightarrow \infty, 
\sum_n a_n=\infty \text{ and } \sum_n \left(\frac{a_n}{\delta_n}\right)^2 <\infty.$$

\item For each $i=1,\ldots,N$ and any $\rho>0$, 
$P(\{ \bar f_{ni} (x_n) \ge 0 \text{ i.o}\} \cap \{ \bar f_{ni} (x_n) < 0 \text{ i.o}\} \mid \{ |x_{ni} - x^*_i| \ge \rho\quad \forall n\}) =0.$

\item The operator $\Upsilon$ satisfies $\delta_n^2 \Upsilon(H_n)^{-1} \rightarrow 0$ a.s. and  $E(\left\| \Upsilon(H_n)^{-1}\right\|^{2+\zeta}) \le \rho$ for some $\zeta, \rho>0$.

\item For any $\tau >0$ and nonempty $S \subseteq \{1,\ldots,N\}$, there exists a $\rho'(\tau,S)>\tau$ such that 
$$ \limsup_{n\rightarrow \infty} \left| \dfrac{\sum_{i \notin S} (x-x^*)_i \bar f_{ni}(x)}{\sum_{i \in S} (x-x^*)_i \bar f_{ni}(x)}               \right| < 1 \text{ a.s.}$$
for all $|(x-x^*)_i| < \tau$ when $i \notin S$ and $|(x-x^*)_i| \ge \rho'(\tau,S)$ when $i\in S$.
\item For some $\alpha_0, \alpha_1>0$ and for all $n$, $\E {\xi_n}^{2} \le \alpha_0$, $\E {\xi_n^{\pm}}^{2} \le \alpha_0$, $\E f(x_n)^{2} \le \alpha_1$,  $\E f(x_n\pm \delta_n d_n)^{2} \le \alpha_1$ and $\E \left(\left\| \Upsilon(\overline H_n) \right\|^2 \mid \F_n\right) \le \alpha_1$. 
\item  $\delta_n = \frac{\delta_0}{(n+1)^{\varsigma}}$, where $\delta_0 > 0$ and $0 < \varsigma \le 1/8$.
\end{enumerate}
The reader is referred to Section II-B of \cite{prashanth2015rdsa} for a detailed discussion of the above assumptions. We remark here that (C1)-(C8) are identical to that in \cite{prashanth2015rdsa}, while (C9) and (C10) introduce minor additional requirements on $\left\| \Upsilon(\overline H_n \right\|^2$ and $\delta_n$, respectively and these are inspired by \cite{spall-jacobian}.

\begin{lemma}(\textbf{Bias in Hessian estimate})
\label{lemma:2rdsa-bias}
Under (C1)-(C10), with $\widehat H_n$ defined according to either \eqref{eq:2rdsa-estimate-unif} or \eqref{eq:2rdsa-estimate-ber}, we have a.s. that\footnote{Here $\widehat H_n(i,j)$ and $\nabla^2_{ij}f(\cdot)$ denote the $(i,j)$th entry in the Hessian estimate $\widehat H_n$ and the true Hessian $\nabla^2 f(\cdot)$, respectively.}, for $i,j = 1,\ldots,N$,
\begin{align}
\left|\E\left[
\left. \widehat H_n(i,j) \right| \F_n \right] - \nabla^2_{ij} f(x_n)\right| = O(\delta_n^2).
\end{align} 
\end{lemma}
\begin{proof}
See Lemma 4 in \cite{prashanth2015rdsa}.
\end{proof}

\begin{theorem}(\textbf{Strong Convergence of Hessian})
\label{thm:2rdsa-H}
Under (C1)-(C10), we have that 
$$\overline H_n \rightarrow \nabla^2 f(x^*) \text{ a.s. as } n\rightarrow \infty.$$ 
In the above, $\overline H_n$ is updated according to \eqref{eq:2rdsa-H}. $\widehat H_n$ defined according to either \eqref{eq:2rdsa-estimate-ber} or \eqref{eq:2rdsa-estimate-unif} and the step-sizes $b_n$ are chosen as suggested in \eqref{eq:wieghts}. 
\end{theorem}
\begin{proof}
For proving the main claim regarding $\overline H_n$, we closely follow the approach used to prove a corresponding result for 2SPSA (see Theorem 1 in \cite{spall-jacobian}). 
The first step is to prove the following:
\begin{align}
\sum_{k=0}^n \dfrac{\delta_k^4 \left(\widehat H_k - \widehat \Psi_k - \E(\widehat H_k \mid \F_k)\right)}{\sum_{i=0}^n \delta_i^4} \rightarrow 0.
\label{eq:step1}
\end{align}

By a completely parallel argument to that used in the proof of Theorem 1 in \cite{spall-jacobian}, we obtain: For any $i,j = 1,\ldots,N$,
\begin{align*}
\E \left[\left((\widehat {H}_k)_{i,j} - (\widehat {\Psi}_k)_{i,j} - \E((\widehat {H}_k)_{i,j} \mid \F_k)\right)^2\right] = O(\delta_k^{-4}).
\end{align*}
Now \eqref{eq:step1} follows by an application of Kronecker's Lemma along with the martingale convergence theorem (see Theorem 6.2.1 of \cite{lahaprobability}).

From Lemma \ref{lemma:2rdsa-bias}, we have 
$$ \E[ \widehat H_k \mid \F_k] = \nabla^2 f(x_n) + O(\delta_n^2) \text{ a.s.}$$
Since the Hessian is continuous near $x_n$ and $x_n$ converges almost surely to $x^*$, we have
\footnote{Since assumptions (C1)-(C10) here are similar to that in \cite{prashanth2015rdsa}, Theorem 5 of \cite{prashanth2015rdsa} holds here as well. In particular, this implies almost sure convergence of $x_n$ to $x^*$.}
\begin{align*}
\sum_{k=0}^n \dfrac{\delta_k^4 \left(\E(\widehat H_k \mid \F_k)\right)}{\sum_{i=0}^n \delta_i^4} 
=&\sum_{k=0}^n \dfrac{\delta_k^4 \left(\nabla^2 f(x_n) + O(\delta_n^2)\right)}{\sum_{i=0}^n \delta_i^4}\\
=&\sum_{k=0}^n \dfrac{\delta_k^4 \left(\nabla^2 f(x^*) + o(1)\right)}{\sum_{i=0}^n \delta_i^4}\\
&\rightarrow \nabla^2 f(x^*) \text{ a.s. as } n \rightarrow \infty.
\end{align*}
The last step above follows from Toeplitz Lemma (see p. 89 of \cite{lahaprobability}) after observing that $\sum_{i=0}^n \delta_i^4 \rightarrow \infty$ due to (C10). 
The main claim now follows since 
$$ \overline H_n = \sum_{k=0}^n \dfrac{\delta_k^4 \left(\widehat H_k - \Psi_k \right)}{\sum_{i=0}^n \delta_i^4}.$$
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%%%%%%%%% Quadratic case
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%We next present a convergence rate result for the special case of a quadratic objective function under the following additional assumptions:
%\begin{enumerate}[label=(\textbf{C\arabic*}),resume]
%\item  $f$ is quadratic and $\nabla^2 f(x^*) > 0$. 
%\item The operator $\Upsilon$ is chosen such that $\E(\parallel \Upsilon(\overline H_n) - \overline H_n\parallel^2) = o(e^{-2wn^{1-r}/(1-r)})$ and $\parallel \Upsilon(H) - H \parallel^2 / (1+\parallel H \parallel^2)$ is uniformly bounded.
%\end{enumerate}
%
%\begin{theorem}(\textbf{Quadratic case - Convergence rate})
%\label{thm:quad-bound}
%Assume (C4), (C10), (C11) and (C12) and also that the setting is noise-free. 
%Let $b_n = b_0/n^r$, $n=1,2,\ldots,k$, where $1/2 < r < 1$ and $0 < b_0 \leq 1$. For notational simplicity, let $H^*=\nabla^2 f(x^*)$. Letting $\Lambda_k = \overline H_k - H^*$, we have 
%\begin{align}
%\text{trace}[\E (\Lambda_n \tr \Lambda_n)] = O(e^{-2b_0n^{1-r} / {1-r}}).
%\label{eq:quad-bigo}
%\end{align}
%\end{theorem}
%\begin{proof}
%Since the setting is noise-free with a quadratic objective, we can rewrite \eqref{eq:hnhat} as follows:
%\begin{align}
 %\widehat H_n =    \Phi_n(\nabla^2 f(x_n)) &+\Psi_{n}(\nabla^2 f(x_n)),\label{eq:hnhat-ext}
%\end{align}
%where $\Psi_n(H)$ is defined in \eqref{eq:psi} and for any matrix $H$, 
%$$\Phi_{n}(H) = [M_n]_{D}\left(d_{n}\tr \, [H]_{D} \, d_{n}\right) +  [M_n]_{N}\left(d_{n}\tr \, [H]_{N} \, d_{n}\right).$$
%
%The proof involves the following steps:
%\begin{description}
  %\item[Step 1:] Here we prove the MSE convergence of $\overline H_k$, i.e., $\E [\Lambda_n\tr \Lambda_n] \rightarrow 0$ a.s. as $n\rightarrow \infty$.
  %\item[Step 2:] We unroll the recursion \eqref{eq:2rdsa-H} and then derive convenient representation for $\text{trace}[\E (\Lambda_n \tr \Lambda_n)]$.
  %\item[Step 3:] We derive the main result in \eqref{eq:quad-bigo} using a proof by contradiction. 
%\end{description}
%
%\noindent\textbf{Step 1: MSE convergence of $\overline H_n$} \\
%This part in exactly the same manner as part (i) in Theorem 3 of \cite{spall-jacobian}.
%
%\noindent\textbf{Step 2: Representation of $\text{trace}[\E (\Lambda_n \tr \Lambda_n)]$} \\
 %From \eqref{eq:2rdsa-H} and \eqref{eq:hnhat-ext},  we have
 %\begin{align}
 %\Lambda_n &= \Lambda_{n-1} - b_n ( H_{n-1} - \hat H_n + \hat \Psi_n) \nonumber\\
%&= (1-b_n) \Lambda_{n-1} - b_n (H^* + \hat \Psi_n - \hat H_n ) \nonumber\\&= (1-b_n) \Lambda_{n-1} - b_n (H^*+\hat \Psi_n -\Phi_n(H^*) - \Psi_n(H^*)\nonumber\\&= (1-b_n) \Lambda_{n-1} - b_n \Psi_n(\Upsilon(\overline H_{n-1})) \nonumber\\& \hspace{2.6cm}+ b_n (\Phi_k(H^*) - H^*)\nonumber\\
%&= (1-b_n) \Lambda_{n-1} - b_n\Psi_n(\Lambda_{n-1}')+ b_n (\Phi_k(H^*) - H^*),\label{eq:step1last}
 %\end{align}
%where $\Lambda_n' = \Upsilon(\overline H_k) - H^*$.
%The equality in \eqref{eq:step1last} follows from \eqref{eq:psi}. 
%
%Unrolling the recursion \eqref{eq:step1last}, we obtain 
 %\begin{align}\label{lambda-exp}
%&  \Lambda_n  = \left[ \prod_{k=1}^n (1-b_k) \right]\Lambda_0 \nonumber\\ 
%&\quad- \sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right] b_k \Psi_k(\Lambda_{k-1}') \nonumber\\ 
%&\quad+ \sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right] b_k (\Phi_k(H^*) - H^*) \hspace{0.2cm} a.s.
 %\end{align}
 %%(note : $\prod_{j=n+1}^n (1-b_j) = 1$ for all n).
 %%Let us  characterise $trace[\E(\Lambda_n\tr \Lambda_n)]$ using \eqref{lambda-exp}. From independence of $d_k$ along k, \eqref{lambda-exp} represent martingale difference sequence, leading to 
%Squaring on both sides and taking expectations, we obtain
 %\begin{align}
 %& \E (\Lambda_n \tr \Lambda_n) =  \left[ \prod_{k=1}^n (1-b_k) \right]^2 \E (\Lambda_0 \tr \Lambda_0)  \nonumber\\ &+ \sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right]^2 b_k^2   \E (\Psi_k(\Lambda_{k-1}') \tr \Psi_k(\Lambda_{k-1}'))  \nonumber\\ &+ \sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right]^2 b_k^2  \nonumber\\& \hspace{2cm} \times \E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*)) \nonumber\\
%&+\sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right]^2 b_k^2 \E\left(\Psi_k \tr (\Phi_k(H^*) - H^*))\right).\label{eq:exp-lambda2}
 %\end{align}
%The equality above uses the fact that $\E(\Psi_k(\Lambda_{k-1}'))=0$, $\E(\Phi_k(H^*) - H^*)=0$, which get rid of the corresponding cross terms with the first term on RHS of \eqref{lambda-exp}. Notice that there are only $n$ terms in the last term in the RHS of \eqref{eq:exp-lambda2} because $d_k$ are identically distributed for each $k$ and across $k$.  
 %
%We now characterize $\text{trace}[\E(\Lambda_n\tr \Lambda_n)]$ using \eqref{eq:exp-lambda2} as follows:
%From the independence of $d_k$'s and $\Lambda_{k-1}'$ and using Cauchy-Schwartz inequality we get 
 %\begin{align}\label{eq:trace}
 %& \text{trace} \left[\E (\Lambda_n \tr \Lambda_n)\right] \leq \left[ \prod_{k=1}^n (1-b_k) \right]^2 \text{trace} \left[\E (\Lambda_0 \tr \Lambda_0)\right]  \nonumber\\ &+ \sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right]^2 b_k^2  \,\,\tau\left(\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')\right)  \nonumber\\ &+ \sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right]^2 b_k^2  \nonumber\\&  \hspace{0.5cm}\times \text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right] + \nonumber\\ &+ \sum_{k=1}^n \left[\prod_{j=k+1}^n (1-b_j)\right]^2 b_k^2   \tau\left(\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')\right)^{1/2} \nonumber\\&  \times \text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right]^{1/2}.
 %\end{align}
%As in the proof of Theorem 3 of \cite{spall-jacobian}, observe that $1-b_k = e^{-b_k}(1-O(b_k^2))$ and since $0 < b_k <1$, we have that the $O(b_k^2)$ term is strictly positive. 
%Letting $\Gamma_{ij} = \sum_{k=i}^j b_k$ with $\Gamma_{nn} = 1$ and $\beta_{kn} = \left[\prod_{i=k+1}^n (1- O(b_i^2))\right]^2$, we can simplify \eqref{eq:trace} as follows:
%\begin{align}\label{eq:wij}
 %& \text{trace} \left[\E (\Lambda_n \tr \Lambda_n)\right] \leq e^{-2 \Gamma_{1n}} \beta_{0n} \text{trace} \left[\E (\Lambda_0 \tr \Lambda_0)\right]  \nonumber\\ &+ e^{-2 \Gamma_{1n}} \sum_{k=1}^n e^{2 \Gamma_{1k}} \beta_{kn} b_k^2  \,\,\tau\left(\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')\right)  \nonumber\\ &+ e^{-2 \Gamma_{1n}} \sum_{k=1}^n e^{2 \Gamma_{1k}} \beta_{kn} b_k^2  \nonumber\\&  \hspace{0.5cm}\times \text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right] \nonumber\\ &+ e^{-2 \Gamma_{1n}} \sum_{k=1}^n e^{2 \Gamma_{1k}} \beta_{kn} b_k^2  \tau\left(\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')\right)^{1/2} \nonumber\\&  \times \text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right]^{1/2}.
 %\end{align} 
%Comparing the sum with integrals, we obtain
%\begin{align*}
%\Gamma_{ij} = \int_i^j \frac{b_0}{x^r} dx + O(1) &= \left(\frac{b_0}{1-r}\right)(j^{1-r}-i^{1-r}) +O(1),
%\end{align*}
%where we have used the facts that $0 < b_k < 1, \forall k \ge 2$ and 
%$\sum_{k=i}^j b_k \to \infty$ as $j-i \to \infty$ since 
%$b_k = b_0/k^r$ with $r > 0.5$.
%
%Observing that $\beta_{kn}$ are uniformly upper-bounded, say by $\bar \beta_n$, we have
%\begin{align}\label{eq:thmwts}
 %& \text{trace} \left[\E (\Lambda_n \tr \Lambda_n)\right] =  e^{-2 \Gamma_{1n}} \beta_{0n} \text{trace} \left[\E (\Lambda_0 \tr \Lambda_0)\right]  \nonumber\\ 
%&+ \bar \beta_n e^{-2 b_0 n^{1-r}/(1-r)} \sum_{k=1}^n e^{2 b_0 k^{1-r}/(1-r)}  \times \frac{b_0^2}{k^{2 r}} \nonumber\\
%& \hspace{3.5cm} \times \tau\left(\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')\right)  \nonumber\\ 
%&+ \bar \beta_n e^{-2 b_0 n^{1-r}/(1-r)} \sum_{k=1}^n e^{2 b_0 k^{1-r}/(1-r)}  \times \frac{b_0^2}{k^{2 r}}  \nonumber\\
%&  \hspace{0.5cm}\times \text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right] \nonumber\\ &+ \bar \beta_n e^{-2 b_0 n^{1-r}/(1-r)} \sum_{k=1}^n e^{2 b_0 k^{1-r}/(1-r)}  \times \frac{b_0^2}{k^{2 r}}  \nonumber\\&\hspace{3.5cm}\times \tau\left(\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')\right)^{1/2}\nonumber\\&\times \text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right]^{1/2}.
%\end{align} 
%
%\noindent\textbf{Step 3: The big-O result on $\text{trace}[\E (\Lambda_n \tr \Lambda_n)]$ convergence} \\
%In comparison to Eq. (7.6) in \cite{spall-jacobian} that corresponds to \eqref{eq:thmwts} for the 2SPSA setting, there are two extra terms - the third and the fourth - in the RHS of \eqref{eq:thmwts}. 
%
%Consider the third term on the RHS of \eqref{eq:thmwts}. As a consequence of (C9) and the construction of random perturbations $d_k$, it can be seen that $\text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right]$ is uniformly bounded above, say by $\top$, independent of $k$. Thus, the third term is equivalent to the following:
%\begin{align}
 %\bar c_n e^{-2 b_0 n^{1-r}/(1-r)} \sum_{k=1}^n e^{2 b_0 k^{1-r}/(1-r)}  \frac{b_0^2}{k^{2 r}} \top.
%\label{eq:term3}
%\end{align}
%Now, observe that $\lim_{n\rightarrow \infty} \sum_{k=1}^n \frac{1}{k^{2 r}} < \infty$ as $1/2 < r < 1$ and $e^{2 b_0 k^{1-r}/(1-r)}$ diverges as $n\rightarrow \infty$ and hence, by Kronecker's Lemma, the term in \eqref{eq:term3} vanishes asymptotically. 
%
%Now consider the fourth term. By using the uniform upper-bound $\top$ on $\text{trace}\left[\E ((\Phi_k(H^*) - H^*) \tr  (\Phi_k(H^*) - H^*))\right]$, we can rewrite  the fourth term in \eqref{eq:thmwts} as follows: 
 %\begin{align}\label{eq:fourthterm}
 %\bar c_n e^{-2 b_0 n^{1-r}/(1-r)} \sum_{k=1}^n e^{2 b_0 k^{1-r}/(1-r)}  \frac{b_0^2}{k^{2 r}} \sqrt{\top} \nonumber \\ \hspace{3cm}\times \tau\left(\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')\right)^{1/2},
 %\end{align}
%where, as in the proof of Theorem 3 of \cite{spall-jacobian}, $\tau(\cdot)$ transforms the $\E (\Lambda_{k-1}' \otimes \Lambda_{k-1}')$ in a linear fashion and then returns the trace of the resulting $N\times N$ matrix.
%
%Part (iii) of Theorem 3 in \cite{spall-jacobian} uses a proof by contradiction to show that the first and second terms in \eqref{eq:thmwts} are both of the order $O(e^{-2b_0n^{1-r} / {1-r}})$. By a completely parallel argument to that used for the second term in \cite{spall-jacobian}, it can be seen that the fourth term in our setting vanishes at a faster rate than the second term.  The claim follows. 
%\end{proof}
